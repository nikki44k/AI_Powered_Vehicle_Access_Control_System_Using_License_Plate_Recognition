# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O5wsCthS-fAwHuxEtAuhJnLBJqq2iJA3

# Build the UI & Create a Streamlit app (ui/app.py)

This section builds a Streamlit web app for vehicle access control. It:

Loads a trained YOLOv8 model and allowed plates list

Detects license plates in uploaded images

Uses Tesseract OCR to read plate numbers

Verifies access based on allowed plate numbers

Displays results with cropped images and access decisions
"""

import os
import cv2
import numpy as np
import pandas as pd
import pytesseract
pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
import streamlit as st
from ultralytics import YOLO

st.set_page_config(page_title="Vehicle Access Control", layout="wide")

"""Load model & allowlist"""

BASE = os.getcwd()
model_path = os.path.join(BASE, 'model', 'yolov8_license_plate_model.pt')
model      = YOLO(model_path)

csv_path   = os.path.join(BASE, 'data', 'allowed_plates.csv')
allowed_df = pd.read_csv(csv_path)
allowed    = set(
    allowed_df['plate_number']
              .astype(str)
              .str.replace(r'[^A-Za-z0-9]', '', regex=True)
              .str.upper()
)


"""OCR & verify helpers"""

def ocr_variants(crop):
    """Return best OCR result among multiple preprocessings."""
    variants = []
    variants.append((crop, '--psm 11'))
    gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)
    _, th = cv2.threshold(gray, 0, 255,
                          cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    variants.append((th, '--psm 7'))
    adapt = cv2.adaptiveThreshold(
        gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,11,2
    )
    variants.append((adapt, '--psm 6'))

    best = ""
    for img, cfg in variants:
        cfg_full = (f"{cfg} --oem 3 "
                    "-c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789")
        txt = pytesseract.image_to_string(img, config=cfg_full).strip()
        if len(txt) > len(best):
            best = txt
    return best

def detect_and_ocr(img: np.ndarray, conf=0.25, pad=5):
    """Run YOLO → crop → OCR. Returns list of (crop, text)."""
    h, w = img.shape[:2]
    # YOLOv8 expects either path or array; passing array directly
    results = model.predict(img, conf=conf, verbose=False)[0]
    outputs = []
    for box in results.boxes.xyxy.cpu().numpy():
        x1,y1,x2,y2 = map(int, box)
        x1, y1 = max(0, x1-pad), max(0, y1-pad)
        x2, y2 = min(w, x2+pad), min(h, y2+pad)
        crop = img[y1:y2, x1:x2]
        txt  = ocr_variants(crop)
        outputs.append((crop, txt))
    return outputs

def verify_plate(text: str) -> bool:
    key = ''.join(ch for ch in text.upper() if ch.isalnum())
    return key in allowed

"""Streamlit layout"""

st.title("AI-Powered Vehicle Access Control")

uploaded = st.file_uploader("Upload an image of a vehicle", type=["png","jpg","jpeg"])
if uploaded is not None:
    # Convert uploaded file to OpenCV image
    file_bytes = np.asarray(bytearray(uploaded.read()), dtype=np.uint8)
    img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)

    st.image(img[:, :, ::-1], caption="Input Image", use_column_width=True)

    # Run detection + OCR
    plates = detect_and_ocr(img, conf=0.2, pad=8)
    if not plates:
        st.warning("No license plate detected.")
    else:
        for i, (crop, txt) in enumerate(plates, start=1):
            clean_txt = txt.replace('\n', '').replace('\r', '').replace(';', '').strip()
            cols = st.columns([1,2])
            with cols[0]:
                st.image(crop[:, :, ::-1], caption=f"Plate #{i}", use_container_width=True)
            with cols[1]:
                st.markdown(f"**OCR Result:** `{clean_txt}`")
                if verify_plate(clean_txt):
                    st.success("✅ Access Granted")
                else:
                    st.error("❌ Access Denied")